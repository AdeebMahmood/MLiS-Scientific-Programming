{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMB5Rc7RU7XadNhVFKsekU7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdeebMahmood/MLiS-Scientific-Programming/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfurnbHPJYMs"
      },
      "source": [
        "from random import seed\r\n",
        "from random import randint\r\n",
        "seed(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIaSK2GYJiEf"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "%matplotlib inline\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from skimage import color, segmentation\r\n",
        "from skimage.segmentation import mark_boundaries\r\n",
        "from skimage.segmentation import slic\r\n",
        "from skimage.measure import regionprops\r\n",
        "from skimage.future import graph\r\n",
        "import networkx as nx\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q21zP5K_JiCB"
      },
      "source": [
        "print(tf.__version__) # check we are using tensorflow v1.15 as this is required for GCN\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPH9wY2YJh_y"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data() #Load the mnist dataset\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YBbSv_hJh9I"
      },
      "source": [
        "#get first image data and label and plot it\r\n",
        "plt.imshow(x_train[0,:,:], cmap='gray_r');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IE7LnEfJh6V"
      },
      "source": [
        "# write a function that preprocesses an input image to have 3 channels in the output. This is required for the segmentation. \r\n",
        "def _preprocess(image): #make image have 3 channels\r\n",
        "  stacked_image = np.stack((image,)*3, axis=-1)\r\n",
        "  return stacked_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uGlBFl5Jh4J"
      },
      "source": [
        "# write a function that takes the image, preprocesses it using the previous function we wrote and then uses the slic function to obtain the segmentation. It requires the number of segments and compactnesss to be set\r\n",
        "def get_slic(image, n_segments, compactness):\r\n",
        "  processed_image = _preprocess(image) #process image\r\n",
        "  #for number_segments in n_segments:\r\n",
        "  output = slic(processed_image, n_segments=n_segments , compactness=compactness) #get segmentation \r\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOmyWP9VJh1Z"
      },
      "source": [
        "# Check that it works by ploting the image and its segmentation\r\n",
        "processed_image = _preprocess(x_train[0,:,:])\r\n",
        "segs = get_slic(x_train[0,:,:], n_segments=50, compactness=10)\r\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 10), sharex=True, sharey=True)\r\n",
        "\r\n",
        "ax[0].imshow(processed_image);\r\n",
        "ax[1].imshow(mark_boundaries(processed_image, segs));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCboyEC7JhzT"
      },
      "source": [
        "def scale_image(image, scale):\r\n",
        "  image = np.repeat(image, scale, axis=0)\r\n",
        "  image = np.repeat(image, scale, axis=1)\r\n",
        "  return(image)\r\n",
        "\r\n",
        "scale = 10 \r\n",
        "scaled_im = scale_image(processed_image, scale)\r\n",
        "scaled_seg = scale_image(segs,scale)\r\n",
        "\r\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 10), sharex=True, sharey=True)\r\n",
        "\r\n",
        "ax[0].imshow(scaled_im);\r\n",
        "ax[1].imshow(mark_boundaries(scaled_im, scaled_seg));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv9vCgaqJhww"
      },
      "source": [
        "# Compute the graph g from the segmentation using mean colors. This can be done using the function rag_mean_colour in graph\r\n",
        "g = graph.rag_mean_color(processed_image, segs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-MVM_AaJhuI"
      },
      "source": [
        "print('Nodes: \\n', g.nodes) #print nodes\r\n",
        "print('Degrees: \\n', g.degree) #print number of degrees of each node (connections)\r\n",
        "print('Edges: \\n', g.edges) # print the connections\r\n",
        "print('Node 0: \\n', g.nodes[0]) #print the properties of the nodes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ScGeN3EJhr-"
      },
      "source": [
        "(g.edges)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9mfKc3cJhg1"
      },
      "source": [
        "#draw the graph \r\n",
        "nx.draw(g, with_labels=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TLhcwbHJz12"
      },
      "source": [
        "A = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],] #get the adjacency matrix from the graph\r\n",
        "print('shape: ', np.shape(A));\r\n",
        "plt.imshow(A);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_axghloLBDo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwRMkvZBJzy1"
      },
      "source": [
        "import os\r\n",
        "import glob\r\n",
        "!pip install trimesh\r\n",
        "import trimesh\r\n",
        "!pip install git+https://github.com/tkipf/gcn.git\r\n",
        "from __future__ import division\r\n",
        "from __future__ import print_function\r\n",
        "from sklearn.neighbors import NearestNeighbors\r\n",
        "from gcn.utils import *\r\n",
        "#from gcn.models import GCN, MLP\r\n",
        "\r\n",
        "import time\r\n",
        "import scipy.sparse as sp\r\n",
        "from scipy.sparse import csr_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DouzhMbAJzuV"
      },
      "source": [
        "tf.compat.v1.app.run \r\n",
        "from gcn.models import GCN, MLP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG320W8KJzsO"
      },
      "source": [
        "DATA_DIR = tf.keras.utils.get_file(\r\n",
        "    \"modelnet.zip\",\r\n",
        "    \"http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\",\r\n",
        "    extract=True,\r\n",
        ")\r\n",
        "DATA_DIR = os.path.join(os.path.dirname(DATA_DIR), \"ModelNet10\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjME_rhjJzpq"
      },
      "source": [
        "mesh = trimesh.load(os.path.join(DATA_DIR, \"chair/train/chair_0001.off\"))\r\n",
        "mesh.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUNGh-OoJzhx"
      },
      "source": [
        "# Convert mesh to point cloud we need to do sampling\r\n",
        "points = trimesh.sample.sample_surface(mesh, 2000) #sample 2000 points from the mesh using the sample function \r\n",
        "\r\n",
        "fig = plt.figure(figsize=(5, 5))\r\n",
        "ax = fig.add_subplot(111, projection=\"3d\")\r\n",
        "ax.scatter(points[:, 0], points[:, 1], points[:, 2])\r\n",
        "ax.set_axis_off()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o543_w68J8ne"
      },
      "source": [
        "# parse through folders of ModelNet to get dataset\r\n",
        "def parse_dataset(num_points=2048):\r\n",
        "\r\n",
        "    train_points = []\r\n",
        "    train_labels = []\r\n",
        "    test_points = []\r\n",
        "    test_labels = []\r\n",
        "    class_map = {}\r\n",
        "    folders = glob.glob(os.path.join(DATA_DIR, \"[!README]*\"))\r\n",
        "\r\n",
        "    for i, folder in enumerate(folders):\r\n",
        "        print(\"processing class: {}\".format(os.path.basename(folder)))\r\n",
        "        # store folder name with ID so we can retrieve later\r\n",
        "        class_map[i] = folder.split(\"/\")[-1]\r\n",
        "        # gather all files\r\n",
        "        train_files = glob.glob(os.path.join(folder, \"train/*\"))\r\n",
        "        test_files = glob.glob(os.path.join(folder, \"test/*\"))\r\n",
        "\r\n",
        "        for f in train_files:\r\n",
        "            train_points.append(trimesh.load(f).sample(num_points))\r\n",
        "            train_labels.append(i)\r\n",
        "\r\n",
        "        for f in test_files:\r\n",
        "            test_points.append(trimesh.load(f).sample(num_points))\r\n",
        "            test_labels.append(i)\r\n",
        "\r\n",
        "    return (\r\n",
        "        np.array(train_points),\r\n",
        "        np.array(test_points),\r\n",
        "        np.array(train_labels),\r\n",
        "        np.array(test_labels),\r\n",
        "        class_map,\r\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTK3Tri2J8ku"
      },
      "source": [
        "npoints = 100 #number of points to sample\r\n",
        "nclasses = 10  #number of classes/labels\r\n",
        "\r\n",
        "train_points, test_points, train_labels, test_labels, CLASS_MAP = parse_dataset(npoints)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XzRZ2LKJ8iC"
      },
      "source": [
        "print('train size:', train_points.shape) # we have 3991 sets of training data each with 1000 points with x,y,z location coordinates\r\n",
        "print('test size:', test_points.shape) # we have 908 sets of test data each with 1000 points with x,y,z location coordinates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HxNyURJJ8aA"
      },
      "source": [
        "i = 1500 #plot the 1500th training sample\r\n",
        "\r\n",
        "fig = plt.figure(figsize=(5, 5))\r\n",
        "ax = fig.add_subplot(111, projection=\"3d\")\r\n",
        "ax.scatter(train_points[i, :, 0], train_points[i, :, 1], train_points[i, :, 2])\r\n",
        "ax.set_axis_off()\r\n",
        "fig.suptitle('label: '+CLASS_MAP[train_labels[i]]) #title is the label\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2Dn3AHcKCjI"
      },
      "source": [
        "def graph_distance(graph):\r\n",
        "  length = dict(nx.all_pairs_shortest_path_length(A))\r\n",
        "  for i in range(max(list(graph.nodes))):\r\n",
        "    for j in list(A.adj[i]):\r\n",
        "      yield(i,j,length[i][j])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY-bX-T7KCgu"
      },
      "source": [
        "def array_nodes(n):\r\n",
        "  arr = []\r\n",
        "  for i in range(n):\r\n",
        "    arr.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiyKlfLNKCeM"
      },
      "source": [
        "def graph_neighbours(graph):\r\n",
        "  length = dict(nx.all_pairs_shortest_path_length(A))\r\n",
        "  for i in range(max(list(graph.nodes))):\r\n",
        "    for j in list(A.adj[i]):\r\n",
        "      yield(i,j)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwIpr3ESKCb7"
      },
      "source": [
        "# this function converts point cloud data into a graph\r\n",
        "def pc2graph(pc, knn, threshold):\r\n",
        "  G = nx.Graph() # initialise networkx graph\r\n",
        "  N = 10 #number of nodes \r\n",
        "\r\n",
        "  ix = array_nodes(N) #make an array with the number of each node\r\n",
        "\r\n",
        "  nn = NearestNeighbors(n_neighbors=knn, metric='euclidean',\r\n",
        "                              leaf_size=15, n_jobs=-1).fit(pc)\r\n",
        "  distances, indices = nn.kneighbors(pc) #returns the distances and indices of the k-nearest neihgbours for each node\r\n",
        "\r\n",
        "  \r\n",
        "  #make a list of pairs of nodes which are neighbours\r\n",
        "  edges = # array of size [N,3] that stores the pair indices and the distances between them\r\n",
        "\r\n",
        "  # add nodes to graph using any function from nx \r\n",
        "\r\n",
        "  # add edges, weighted by the distances between the pairs using any function from nx\r\n",
        "\r\n",
        "  return G"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwejPmpKKCZY"
      },
      "source": [
        "indices.reshape(,2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWyxI-VyKCW-"
      },
      "source": [
        "samples = [[0, 0, 2], [1, 0, 0], [0, 0, 1],[1,0,0]]\r\n",
        "neigh = NearestNeighbors(n_neighbors=2, radius=0.4)\r\n",
        "neigh.fit(samples)\r\n",
        "a,b = neigh.kneighbors(samples)\r\n",
        "b.reshape(4,2)\r\n",
        "print(b)\r\n",
        "print(b.reshape(4,2)[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryU7eyLFKCUX"
      },
      "source": [
        "pc = train_points[0,:,:] # point cloud data\r\n",
        "knn = 8 #number of neighbours\r\n",
        "threshold = 20 # minimum distance of nodes to be a neighbour\r\n",
        "G = pc2graph(pc, knn, threshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9c-dbRpKLzx"
      },
      "source": [
        "def Making_Basic_Graph(n):\r\n",
        "  A = nx.Graph()\r\n",
        "  for i in range(n):\r\n",
        "    A.add_nodes_from([randint(0,n),randint(0,n)])\r\n",
        "  for j in range(randint(0,3*n)):\r\n",
        "    A.add_edge(randint(0,n),randint(0,n))\r\n",
        "  return(A)\r\n",
        "\r\n",
        "#A.add_nodes_from([1, 2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpQ-4R2BKLxF"
      },
      "source": [
        "B = nx.Graph()\r\n",
        "B.add_nodes_from(range(9))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQlV6oocKLuu"
      },
      "source": [
        "A = Making_Basic_Graph(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSx4c9huKLsX"
      },
      "source": [
        "nx.draw(A)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}